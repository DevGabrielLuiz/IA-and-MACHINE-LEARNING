{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F \n",
    "import torchvision\n",
    "from time import time\n",
    "from torchvision import datasets,transforms\n",
    "from torch import nn,optim\n",
    "\n",
    "transform = transforms.ToTensor() # definindo a conversão de imagens para tensor \n",
    "\n",
    "trainset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform) # Carrega a parte de treino do dataset \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) # Cria um buffer para pegar os dados por partes\n",
    "\n",
    "valset = datasets.MNIST('./MNIST_data', download=True, train=False, transform=transform) # Carrega parte de validação do dataset \n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True) # Cria um buffer para pegar os dados por partes \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "imagens, etiquetas = next(dataiter)\n",
    "plt.imshow(imagens[0].numpy().squeeze(),cmap='gray_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(imagens[0].shape) # Para verificar as dimensões do tensor de cada imagem \n",
    "print(etiquetas[0].shape) # Para verificar as dimensões do tensor de cada etiqueta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Modelo, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 128) # camada de entrada, 784 neurônios que se ligam a 128\n",
    "        self.linear2 = nn.Linear(128, 64) # Camada interna 1, 128 neurônios que se ligam a 64\n",
    "        self.linear2 = nn.Linear(64, 10) # Camada interna 2, 64 neurônios que se ligam a 10\n",
    "        # para a camada de saida não é necessario definir nada pois só precisamos pegar o output da camada interna 2\n",
    "\n",
    "def forward(self,X):\n",
    "    X = F.relu(self.linear1(X)) # função de ativação da camada de entrada para a camada interna 1 \n",
    "    X = F.relu(self.linear2(X)) # função de ativação da camada interna 1 para a camada interna 2 \n",
    "    X = self.linear3(X) # Função de ativação da camada interna 2 para a camada de saida, nesse caso f(x) = x\n",
    "    return F.log_softmax(X, dim=1) # Dados utilizados para calcular a perda       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino(modelo, trainloader, device):\n",
    "    \n",
    "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) # defina a política de atualizaçãi dos pesos e das bias\n",
    "    inicio = time() # timer para sabermos quanto tempo levou o treino\n",
    "    \n",
    "    criterio = nn.NLLLoss() #definindo o criterio para calcular a perda\n",
    "    EPOCHS = 10 # numero de epochs que o algoritmo rodará\n",
    "    modelo.train() # ativando o modo de treinamento do modelo \n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        perda_acumulada = 0 # inicialização da perda acumulada da epoch em questão\n",
    "        \n",
    "        for imagens, etiquetas, in trainloader:\n",
    "            \n",
    "            imagens = imagens.view(imagens.shape[0], -1) # convertendo as imagens para \"vetores\" de 28*28 casas para ficarem compativeis com a  \n",
    "            otimizador.zero_grad() # zerando os gradientes por conta do ciclo anterior \n",
    "            \n",
    "            output = modelo(imagens.to(device)) #colocando os dados no modelo \n",
    "            perda_instantanea = criterio(output, etiquetas.to(device)) # calculando a perda da epoch em questão\n",
    "            \n",
    "            perda_instantanea.backward() #back propagation a partir da perda \n",
    "            \n",
    "            otimizador.step() #atualizando os pesos e a bias \n",
    "            \n",
    "            perda_acumulada += perda_instantanea.item() # atualização da perda perda_acumulada\n",
    "        \n",
    "        else:\n",
    "            print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
    "    print(\"\\n Tempo de treino (em minutos) =\", (time()-inicio/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacao(modelo, valloader, device):\n",
    "    conta_corretas, conta_todos = 0, 0\n",
    "    for imagens, etiquetas in valloader:\n",
    "        for i in range(len(etiquetas)):\n",
    "            img = imagens[i].view(1, 784)\n",
    "            # desativar o autoograd para acelerar a validação. Grafos computacionais dinâmicos tem um custo alto de processamento\n",
    "            with torch.no_grad():\n",
    "                logps = modelo(img.to(device)) #output do modelo em escala logaritmica\n",
    "                \n",
    "        ps = torch.exp(logps) #converte o output para escala normal(lembrando que é um tensor)\n",
    "        probab = list(ps.cpu().numpy()[0])\n",
    "        etiqueta_pred = probab.index(max(probab)) # converte o tensor em número, no cadom o número que o modelo previu\n",
    "        etiqueta_certa = etiquetas.numpy()[i]\n",
    "        if (etiqueta_certa == etiqueta_pred): # Compara a previsão com o valor correto\n",
    "            conta_corretas += 1 \n",
    "        conta_todos += 1 \n",
    "        \n",
    "    print(\"Total de imagens testadas =\", conta_todos)\n",
    "    print(\"\\nPrecisão do modelo = {}%\".format(conta_corretas*100/conta_todos))\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Modelo(\n",
       "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = Modelo()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelo.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
